{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 20:15:27.012047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 20:15:27.012065: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_categorical' from 'keras.utils' (/home/aminuninnova/.local/lib/python3.8/site-packages/keras/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# import confusion_matrix_pretty_print\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# from sklearn.metrics import confusion_matrix,classification_report,precision_score,auc,precision_recall_curve,roc_curve\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# import keras\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Conv2D, Flatten, Softmax, Dropout\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/home/aminuninnova/.local/lib/python3.8/site-packages/keras/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import confusion_matrix_pretty_print\n",
    "# from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix,classification_report,precision_score,auc,precision_recall_curve,roc_curve\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Softmax, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "# from keras import metrics as kmetr\n",
    "# from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Hold out Zeros\n",
    "\n",
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "\n",
    "# data[data.iloc[:,2]==0].to_csv('../../triple_cosineSNF(zeros).csv',index=False)\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "# data = data[data['2']!=0]\n",
    "# data.to_csv('triple_cosineSNF(-1and1).csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTrain = pd.read_csv('../../triple42702.csv')\n",
    "# dataTest = pd.read_csv('../../tripleTest.csv')\n",
    "# dataTest = pd.read_csv('../../triple_cosineSNF(zeros).csv')\n",
    "\n",
    "# print(dataTest.shape,dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataTrain.values[:,3:]\n",
    "# y_train = dataTrain.values[:,2].astype(int)\n",
    "# del dataTrain\n",
    "# # X_test = dataTest.values[:,3:]\n",
    "# # y_test = dataTest.values[:,2].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainNum = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# # y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# # y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataTrain.values[:,3:]\n",
    "# y_train = dataTrain.values[:,2].astype(int)\n",
    "# del dataTrain\n",
    "# trainNum = len(X_train)\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# y_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 13, 68, 128)       2176      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 65, 32)        65568     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 62, 8)          4104      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3472)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                111136    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 183,266\n",
      "Trainable params: 183,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #create model\n",
    "# model = Sequential()\n",
    "# #add model layers\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# # model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# # model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "# model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense( 64, activation='relu'))\n",
    "# model.add(Dense( 32, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Dense( 16, activation='relu'))\n",
    "# model.add(Dense( 8, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense( 2, activation='sigmoid'))\n",
    "# # model.add(Softmax(128))\n",
    "# model.summary()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense( 64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense( 16, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# model.add(Softmax(128))\n",
    "model.summary()\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='hinge', optimizer=adam, metrics=[kmetr.categorical_accuracy])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ## Minist\n",
    "\n",
    "### Load the model's saved weights.\n",
    "model.load_weights('cnn43110(1and-1)_rivised_5_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### plotting model\n",
    "# plot_model(model,show_shapes = True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### train the model\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n",
    "# # model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Saveing the Model\n",
    "# model.save_weights('Weight/cnn42702(1and-1)_without softmax.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# # y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# # y_test[0]\n",
    "\n",
    "\n",
    "# #predict first 4 images in the test set\n",
    "# predit = model.predict(X_test)\n",
    "# predit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #actual results for first 4 images in test set\n",
    "# print(predit[:4])\n",
    "# predit[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "# prec, rec, thr = precision_recall_curve(y_test[:,0], predit[:,0])\n",
    "# aupr_val = auc(rec, prec)\n",
    "# fpr, tpr, thr = roc_curve(y_test[:,0], predit[:,0])\n",
    "# auc_val = auc(fpr, tpr)\n",
    "# print(aupr_val,auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(list(range(1,11)),model.history.history['acc'])\n",
    "# plt.plot(list(range(1,11)),model.history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(list(range(1,11)),model.history.history['loss'])\n",
    "# plt.plot(list(range(1,11)),model.history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predit\n",
    "# predit[:,0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predicts = []\n",
    "# for a,b in predit:\n",
    "#     if a >=b:\n",
    "#         predicts.append(0)\n",
    "#     else:\n",
    "#         predicts.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts = []\n",
    "# e = d = z = 0\n",
    "\n",
    "# for a,b in predit:\n",
    "#     if a >=0.6:\n",
    "#         predicts.append(0)\n",
    "#         d += 1\n",
    "#     elif b>=0.6:\n",
    "#         predicts.append(2)\n",
    "#         e += 1\n",
    "#     else:\n",
    "#         predicts.append(1)\n",
    "#         z += 1\n",
    "# print('degrassive', d, 'enhancive', e, 'zeros', z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278946"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((568*568-568)-43110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrassive 11072 enhancive 15409 zeros 4491\n",
      "degrassive 19798 enhancive 38066 zeros 7198\n"
     ]
    }
   ],
   "source": [
    "zeroIndexes = []\n",
    "predicts = []\n",
    "e = d = z = 0\n",
    "zeroIndexes = []\n",
    "DegIndexes = []\n",
    "EnhIndexes = []\n",
    "k = 0\n",
    "for i in range(0,278946,46491):\n",
    "    j = i + 46491\n",
    "    # X_train = dataTrain.values[:,3:]\n",
    "    # y_train = dataTrain.values[:,2].astype(int)\n",
    "    # del dataTrain\n",
    "    X_test = pd.read_csv('../../triple_cosineSNF(zeros)_rivised.csv').values[i:j, 3:]\n",
    "#     y_test = dataTest.values[i:j,2].astype(int)\n",
    "\n",
    "    testNum = len(X_test)\n",
    "\n",
    "    #reshape data to fit model\n",
    "    # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "    X_test = X_test.reshape(testNum, 16, 71, 1)\n",
    "\n",
    "    # y_train = y_train + 1\n",
    "#     y_test  = y_test + 1\n",
    "    # y_train = y_train / 2\n",
    "#     y_test  = y_test / 2\n",
    "    # print(y_train[0], y_test[0])\n",
    "\n",
    "    #one-hot encode target column\n",
    "    # y_train = to_categorical(y_train)\n",
    "#     y_test = to_categorical(y_test)\n",
    "    # y_test[0]\n",
    "\n",
    "\n",
    "    #predict first 4 images in the test set\n",
    "    predit = model.predict(X_test)\n",
    "    X_test = []\n",
    "    \n",
    "    pd.DataFrame(predit).to_csv('predict_(-1 and +1 model)' + str(k) + '_rivised.csv', index=False)\n",
    "#     predit\n",
    "    k += 1\n",
    "    f = 0\n",
    "    for a,b in predit:\n",
    "        if a >=0.95:\n",
    "            predicts.append(0)\n",
    "            d += 1\n",
    "            DegIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b>=0.95:\n",
    "            predicts.append(2)\n",
    "            e += 1\n",
    "            EnhIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b <=0.2 and a <= 0.2:\n",
    "            predicts.append(1)\n",
    "            z += 1\n",
    "            zeroIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "#     predit = []\n",
    "    print('degrassive', d, 'enhancive', e, 'zeros', z)\n",
    "    pd.DataFrame(EnhIndexes).to_csv('enhansive indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    EnhIndexes = []\n",
    "    \n",
    "    pd.DataFrame(DegIndexes).to_csv('Degrassive indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    DegIndexes = []\n",
    " \n",
    "    pd.DataFrame(zeroIndexes).to_csv('zero indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    zeroIndexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(zeroIndexes).to_csv('zero indexes_without softmax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# cm = confusion_matrix(list(predicts), list((dataTest.values[:,2]+1)))\n",
    "# print(cm)\n",
    "\n",
    "# CR = classification_report(list((dataTest.values[:,2]+1)),list(predicts))\n",
    "# print(CR)\n",
    "# print(145/4702)\n",
    "# # i=0\n",
    "# # for j in list(data.values[9500:,2]+1):\n",
    "# #     if j==1:\n",
    "# #         i +=1\n",
    "# # print(i)\n",
    "\n",
    "# # plt.show()\n",
    "# plot_confusion_matrix_from_data(list((dataTest.values[:,2]+1)), list(predicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(predit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,0].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,1].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Zero Drugs')\n",
    "plt.xlabel('Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Degrassive Drugs')\n",
    "plt.xlabel('Degressive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,2], hist=True, kde=False, \n",
    "#              bins=int(100), color = 'green',\n",
    "#              hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('both of Degressive and Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
