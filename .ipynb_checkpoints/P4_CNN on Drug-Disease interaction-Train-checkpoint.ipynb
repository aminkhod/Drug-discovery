{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 21:05:01.821601: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-08 21:05:01.821645: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import confusion_matrix_pretty_print\n",
    "from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_score,\\\n",
    "auc, precision_recall_curve, roc_curve\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Softmax, Dropout, MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics as kmetr\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>897</th>\n",
       "      <th>898</th>\n",
       "      <th>899</th>\n",
       "      <th>900</th>\n",
       "      <th>901</th>\n",
       "      <th>902</th>\n",
       "      <th>903</th>\n",
       "      <th>904</th>\n",
       "      <th>905</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21224</td>\n",
       "      <td>0.22535</td>\n",
       "      <td>0.20879</td>\n",
       "      <td>0.21429</td>\n",
       "      <td>0.22045</td>\n",
       "      <td>0.21995</td>\n",
       "      <td>0.21481</td>\n",
       "      <td>0.22678</td>\n",
       "      <td>0.171880</td>\n",
       "      <td>0.195290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.214340</td>\n",
       "      <td>0.042681</td>\n",
       "      <td>0.21672</td>\n",
       "      <td>0.22260</td>\n",
       "      <td>0.061238</td>\n",
       "      <td>0.117210</td>\n",
       "      <td>0.106890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18447</td>\n",
       "      <td>0.19556</td>\n",
       "      <td>0.17976</td>\n",
       "      <td>0.19279</td>\n",
       "      <td>0.19957</td>\n",
       "      <td>0.19913</td>\n",
       "      <td>0.15050</td>\n",
       "      <td>0.18458</td>\n",
       "      <td>0.153390</td>\n",
       "      <td>0.167330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031154</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039694</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>0.073066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.18856</td>\n",
       "      <td>0.20725</td>\n",
       "      <td>0.19338</td>\n",
       "      <td>0.19008</td>\n",
       "      <td>0.18969</td>\n",
       "      <td>0.19935</td>\n",
       "      <td>0.19960</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.217270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083906</td>\n",
       "      <td>0.09446</td>\n",
       "      <td>0.233910</td>\n",
       "      <td>0.159050</td>\n",
       "      <td>0.31350</td>\n",
       "      <td>0.13854</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.095524</td>\n",
       "      <td>0.065253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.14088</td>\n",
       "      <td>0.16898</td>\n",
       "      <td>0.12224</td>\n",
       "      <td>0.12577</td>\n",
       "      <td>0.16223</td>\n",
       "      <td>0.16180</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.14988</td>\n",
       "      <td>0.095618</td>\n",
       "      <td>0.065642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123260</td>\n",
       "      <td>0.06296</td>\n",
       "      <td>0.190130</td>\n",
       "      <td>0.166560</td>\n",
       "      <td>0.18835</td>\n",
       "      <td>0.18332</td>\n",
       "      <td>0.101120</td>\n",
       "      <td>0.083167</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26667</td>\n",
       "      <td>0.26453</td>\n",
       "      <td>0.26898</td>\n",
       "      <td>0.26678</td>\n",
       "      <td>0.25926</td>\n",
       "      <td>0.25875</td>\n",
       "      <td>0.19399</td>\n",
       "      <td>0.26071</td>\n",
       "      <td>0.169080</td>\n",
       "      <td>0.257440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099855</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.061293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 907 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        6        7  \\\n",
       "0  0.21224  0.22535  0.20879  0.21429  0.22045  0.21995  0.21481  0.22678   \n",
       "1  0.18447  0.19556  0.17976  0.19279  0.19957  0.19913  0.15050  0.18458   \n",
       "2  0.19660  0.18856  0.20725  0.19338  0.19008  0.18969  0.19935  0.19960   \n",
       "3  0.14088  0.16898  0.12224  0.12577  0.16223  0.16180  0.11220  0.14988   \n",
       "4  0.26667  0.26453  0.26898  0.26678  0.25926  0.25875  0.19399  0.26071   \n",
       "\n",
       "          8         9  ...       897      898       899       900      901  \\\n",
       "0  0.171880  0.195290  ...  0.016679  0.00000  0.214340  0.042681  0.21672   \n",
       "1  0.153390  0.167330  ...  0.031154  0.00000  0.000000  0.039694  0.00000   \n",
       "2  0.150000  0.217270  ...  0.083906  0.09446  0.233910  0.159050  0.31350   \n",
       "3  0.095618  0.065642  ...  0.123260  0.06296  0.190130  0.166560  0.18835   \n",
       "4  0.169080  0.257440  ...  0.099855  0.00000  0.061293  0.000000  0.00000   \n",
       "\n",
       "       902       903       904       905  y  \n",
       "0  0.22260  0.061238  0.117210  0.106890  0  \n",
       "1  0.00000  0.114370  0.073066  0.000000  0  \n",
       "2  0.13854  0.039971  0.095524  0.065253  0  \n",
       "3  0.18332  0.101120  0.083167  0.157730  0  \n",
       "4  0.00000  0.000000  0.000000  0.000000  0  \n",
       "\n",
       "[5 rows x 907 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### test & train split\n",
    "data = pd.read_csv('../F_Drug-Disease_SMOTE.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.iloc[:int(0.9*len(data.iloc[:,2])),:].to_csv('../trainSaved F(Drug-Disease).csv',index=False)\n",
    "# data.iloc[int(0.9*len(data.iloc[:,2])):,:].to_csv('../testSaved F(Drug-Disease).csv',index=False)\n",
    "                 \n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTrain = pd.read_csv('../trainSaved F(Drug-Disease).csv')\n",
    "# dataTest = pd.read_csv('../testSaved F(Drug-Disease).csv')\n",
    "# dataTest = pd.read_csv('../../triple_cosineSNF(zeros).csv')\n",
    "# print(dataTest.shape,dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = data.iloc[int(0.3*len(data)):,:]\n",
    "dataTest = data.iloc[:int(0.3*len(data)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231433, 907)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99185, 907)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "906/2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataTrain.values[:,:-1]\n",
    "y_train = dataTrain['y'].values.astype(int)\n",
    "trainNum = len(X_train)\n",
    "del dataTrain\n",
    "\n",
    "X_test = dataTest.values[:,:-1]\n",
    "y_test = dataTest['y'].values.astype(int)\n",
    "testNum = len(X_test)\n",
    "del data\n",
    "\n",
    "transformer = Normalizer().fit(X_train)  # fit does nothing.\n",
    "X_train = transformer.transform(X_train)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "#reshape data to fit model\n",
    "X_train = X_train.reshape(trainNum,6,151,1)\n",
    "X_test = X_test.reshape(testNum,6,151,1)\n",
    "\n",
    "# y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# print(y_train[0:5], y_test[0:5])\n",
    "\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "# y_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 6, 151, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 151, 32)        32800     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 6, 151, 16)        8208      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 151, 8)         2056      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 75, 8)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1800)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                57632     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,850\n",
      "Trainable params: 101,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aminuninnova/.local/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# #create model\n",
    "# model = Sequential()\n",
    "# #add model layers\n",
    "# model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# # model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# # model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "# model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense( 64, activation='relu'))\n",
    "# model.add(Dense( 32, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Dense( 16, activation='relu'))\n",
    "# model.add(Dense( 8, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense( 2, activation='sigmoid'))\n",
    "# # model.add(Softmax(128))\n",
    "# model.summary()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=4, activation='relu', padding='same',\\\n",
    "                 input_shape=(6,151,1)))\n",
    "# model.add(Conv2D(64, kernel_size=4, activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=4, activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, kernel_size=4, activation='relu', padding='same'))\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=4, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense( 32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Dense( 16, activation='relu'))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "# model.add(Softmax(128))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "adam = tf.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='hinge', optimizer=adam, metrics=[kmetr.categorical_accuracy])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\\\n",
    "              metrics=['categorical_accuracy']) ## Minist\n",
    "\n",
    "### Load the model's saved weights.\n",
    "# model.load_weights('cnn_4_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# #### plotting model\n",
    "plot_model(model,show_shapes = True, to_file='model .png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   2/7233 [..............................] - ETA: 9:10 - loss: 0.5493 - categorical_accuracy: 0.7656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 21:15:30.210822: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 838713192 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 227/7233 [..............................] - ETA: 8:38 - loss: 0.5955 - categorical_accuracy: 0.7113"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#compile model using accuracy to measure model performance\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#                 1: 95\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#                }\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### train the model\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "# from sklearn.utils import class_weight\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(y_train),\n",
    "#                                                  y_train)\n",
    "# class_weight = {0: 5,\n",
    "#                 1: 95\n",
    "#                }\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2)\n",
    "#                     , class_weight=class_weight)\n",
    "# history = model.fit(X_train, y_train, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saveing the Model\n",
    "model.save_weights('cnn_4_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predit = model.predict(X_test)\n",
    "#actual results for first 4 images in test set\n",
    "print(predit[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_test[:,1], predit[:,1])\n",
    "aupr_val = auc(rec, prec)\n",
    "fpr, tpr, thr = roc_curve(y_test[:,1], predit[:,1])\n",
    "auc_val = auc(fpr, tpr)\n",
    "print(aupr_val,auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(list(range(1,5)),history.history['categorical_accuracy'])\n",
    "plt.plot(list(range(1,5)),history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(list(range(1,5)),history.history['loss'])\n",
    "plt.plot(list(range(1,5)),history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predit\n",
    "# predit[:,0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for a,b in predit:\n",
    "    if a >=b:\n",
    "        predicts.append(0)\n",
    "    else:\n",
    "        predicts.append(1)\n",
    "len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts1 = []\n",
    "# e = d = z = 0\n",
    "\n",
    "# for a,b in predit:\n",
    "#     if a >=0.90:\n",
    "#         predicts1.append(0)\n",
    "#         d += 1\n",
    "#     elif b>=0.95:\n",
    "#         predicts1.append(2)\n",
    "#         e += 1\n",
    "#     elif a<=0.05 and b<=0.1:\n",
    "#         predicts1.append(1)\n",
    "#         z += 1\n",
    "# print('degrassive', d, 'enhancive', e, 'zeros', z)\n",
    "# print(\"\"\"\n",
    "# Epoch04: degrassive 224 enhancive 2939 zeros 40\n",
    "# Epoch05: degrassive 280 enhancive 2823 zeros 39\n",
    "# Epoch06: degrassive 233 enhancive 2879 zeros 79\n",
    "# Epoch07: degrassive 203 enhancive 2926 zeros 134\n",
    "# Epoch08: degrassive 224 enhancive 2895 zeros 180\n",
    "# Epoch09: degrassive 191 enhancive 2856 zeros 191\n",
    "# Epoch10: degrassive 189 enhancive 2821 zeros 246\n",
    "# Epoch11: degrassive 164 enhancive 2581 zeros 235\n",
    "# Epoch12: degrassive 166 enhancive 2454 zeros 266\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(list((dataTest.values[:,2]+1)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(list(predicts), list((dataTest.values[:,2])))\n",
    "print(cm)\n",
    "\n",
    "CR = classification_report(list((dataTest.values[:,2])),list(predicts))\n",
    "print(CR)\n",
    "# print(145/4702)\n",
    "# i=0\n",
    "# for j in list(data.values[9500:,2]+1):\n",
    "#     if j==1:\n",
    "#         i +=1\n",
    "# print(i)\n",
    "\n",
    "# plt.show()\n",
    "plot_confusion_matrix_from_data(list((dataTest.values[:,2])), list(predicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(predit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).plot.density()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,0].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,1].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('Interaction drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('None Interaction drugs Probability')\n",
    "plt.ylabel('frequency distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('all drugs Probability')\n",
    "plt.ylabel('frequency distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
