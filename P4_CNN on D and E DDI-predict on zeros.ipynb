{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import confusion_matrix_pretty_print\n",
    "# from confusion_matrix_pretty_print import plot_confusion_matrix_from_data\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix,classification_report,precision_score,auc,precision_recall_curve,roc_curve\n",
    "\n",
    "# import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Softmax, Dropout\n",
    "from keras import optimizers\n",
    "# from keras import metrics as kmetr\n",
    "# from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Hold out Zeros\n",
    "\n",
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "\n",
    "# data[data.iloc[:,2]==0].to_csv('../../triple_cosineSNF(zeros).csv',index=False)\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../../saved F(triple_cosineSNF).csv')\n",
    "# data = data[data['2']!=0]\n",
    "# data.to_csv('triple_cosineSNF(-1and1).csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTrain = pd.read_csv('../../triple42702.csv')\n",
    "# dataTest = pd.read_csv('../../tripleTest.csv')\n",
    "# dataTest = pd.read_csv('../../triple_cosineSNF(zeros).csv')\n",
    "\n",
    "# print(dataTest.shape,dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataTrain.values[:,3:]\n",
    "# y_train = dataTrain.values[:,2].astype(int)\n",
    "# del dataTrain\n",
    "# # X_test = dataTest.values[:,3:]\n",
    "# # y_test = dataTest.values[:,2].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainNum = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# # y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# # y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = dataTrain.values[:,3:]\n",
    "# y_train = dataTrain.values[:,2].astype(int)\n",
    "# del dataTrain\n",
    "# trainNum = len(X_train)\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# y_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 13, 68, 128)       2176      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 65, 32)        65568     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 62, 8)          4104      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3472)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                111136    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 183,266\n",
      "Trainable params: 183,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/amin/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #create model\n",
    "# model = Sequential()\n",
    "# #add model layers\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# # kernel_initializer='uniform',\n",
    "# model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# # model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# # model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "# model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense( 64, activation='relu'))\n",
    "# model.add(Dense( 32, activation='relu'))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.4))\n",
    "# # model.add(Dense( 16, activation='relu'))\n",
    "# model.add(Dense( 8, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense( 2, activation='sigmoid'))\n",
    "# # model.add(Softmax(128))\n",
    "# model.summary()\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "# kernel_initializer='uniform',\n",
    "model.add(Conv2D(128, kernel_size=4, activation='relu', input_shape=(16,71,1)))\n",
    "# model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=4, activation='relu'))\n",
    "# model.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "model.add(Conv2D(8, kernel_size=4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense( 64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense( 16, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "# model.add(Softmax(128))\n",
    "model.summary()\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "# model.compile(loss='hinge', optimizer=adam, metrics=[kmetr.categorical_accuracy])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) ## Minist\n",
    "\n",
    "### Load the model's saved weights.\n",
    "model.load_weights('cnn43110(1and-1)_rivised_5_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### plotting model\n",
    "# plot_model(model,show_shapes = True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### train the model\n",
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n",
    "# # model.fit(X_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Saveing the Model\n",
    "# model.save_weights('Weight/cnn42702(1and-1)_without softmax.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train = dataTrain.values[:,3:]\n",
    "# # y_train = dataTrain.values[:,2].astype(int)\n",
    "# # del dataTrain\n",
    "# X_test = dataTest.values[:,3:]\n",
    "# y_test = dataTest.values[:,2].astype(int)\n",
    "\n",
    "# testNum = len(X_test)\n",
    "\n",
    "# #reshape data to fit model\n",
    "# # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "# X_test = X_test.reshape(testNum,16,71,1)\n",
    "\n",
    "# # y_train = y_train + 1\n",
    "# y_test  = y_test + 1\n",
    "# # y_train = y_train / 2\n",
    "# y_test  = y_test / 2\n",
    "# # print(y_train[0], y_test[0])\n",
    "\n",
    "# #one-hot encode target column\n",
    "# # y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# # y_test[0]\n",
    "\n",
    "\n",
    "# #predict first 4 images in the test set\n",
    "# predit = model.predict(X_test)\n",
    "# predit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #actual results for first 4 images in test set\n",
    "# print(predit[:4])\n",
    "# predit[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "# prec, rec, thr = precision_recall_curve(y_test[:,0], predit[:,0])\n",
    "# aupr_val = auc(rec, prec)\n",
    "# fpr, tpr, thr = roc_curve(y_test[:,0], predit[:,0])\n",
    "# auc_val = auc(fpr, tpr)\n",
    "# print(aupr_val,auc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(list(range(1,11)),model.history.history['acc'])\n",
    "# plt.plot(list(range(1,11)),model.history.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(list(range(1,11)),model.history.history['loss'])\n",
    "# plt.plot(list(range(1,11)),model.history.history['val_loss'])\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predit\n",
    "# predit[:,0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predicts = []\n",
    "# for a,b in predit:\n",
    "#     if a >=b:\n",
    "#         predicts.append(0)\n",
    "#     else:\n",
    "#         predicts.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts = []\n",
    "# e = d = z = 0\n",
    "\n",
    "# for a,b in predit:\n",
    "#     if a >=0.6:\n",
    "#         predicts.append(0)\n",
    "#         d += 1\n",
    "#     elif b>=0.6:\n",
    "#         predicts.append(2)\n",
    "#         e += 1\n",
    "#     else:\n",
    "#         predicts.append(1)\n",
    "#         z += 1\n",
    "# print('degrassive', d, 'enhancive', e, 'zeros', z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278946"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((568*568-568)-43110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrassive 11072 enhancive 15409 zeros 4491\n",
      "degrassive 19798 enhancive 38066 zeros 7198\n"
     ]
    }
   ],
   "source": [
    "zeroIndexes = []\n",
    "predicts = []\n",
    "e = d = z = 0\n",
    "zeroIndexes = []\n",
    "DegIndexes = []\n",
    "EnhIndexes = []\n",
    "k = 0\n",
    "for i in range(0,278946,46491):\n",
    "    j = i + 46491\n",
    "    # X_train = dataTrain.values[:,3:]\n",
    "    # y_train = dataTrain.values[:,2].astype(int)\n",
    "    # del dataTrain\n",
    "    X_test = pd.read_csv('../../triple_cosineSNF(zeros)_rivised.csv').values[i:j, 3:]\n",
    "#     y_test = dataTest.values[i:j,2].astype(int)\n",
    "\n",
    "    testNum = len(X_test)\n",
    "\n",
    "    #reshape data to fit model\n",
    "    # X_train = X_train.reshape(trainNum,16,71,1)\n",
    "    X_test = X_test.reshape(testNum, 16, 71, 1)\n",
    "\n",
    "    # y_train = y_train + 1\n",
    "#     y_test  = y_test + 1\n",
    "    # y_train = y_train / 2\n",
    "#     y_test  = y_test / 2\n",
    "    # print(y_train[0], y_test[0])\n",
    "\n",
    "    #one-hot encode target column\n",
    "    # y_train = to_categorical(y_train)\n",
    "#     y_test = to_categorical(y_test)\n",
    "    # y_test[0]\n",
    "\n",
    "\n",
    "    #predict first 4 images in the test set\n",
    "    predit = model.predict(X_test)\n",
    "    X_test = []\n",
    "    \n",
    "    pd.DataFrame(predit).to_csv('predict_(-1 and +1 model)' + str(k) + '_rivised.csv', index=False)\n",
    "#     predit\n",
    "    k += 1\n",
    "    f = 0\n",
    "    for a,b in predit:\n",
    "        if a >=0.95:\n",
    "            predicts.append(0)\n",
    "            d += 1\n",
    "            DegIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b>=0.95:\n",
    "            predicts.append(2)\n",
    "            e += 1\n",
    "            EnhIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "        elif b <=0.2 and a <= 0.2:\n",
    "            predicts.append(1)\n",
    "            z += 1\n",
    "            zeroIndexes.append(i + f)\n",
    "            f += 1\n",
    "            \n",
    "#     predit = []\n",
    "    print('degrassive', d, 'enhancive', e, 'zeros', z)\n",
    "    pd.DataFrame(EnhIndexes).to_csv('enhansive indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    EnhIndexes = []\n",
    "    \n",
    "    pd.DataFrame(DegIndexes).to_csv('Degrassive indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    DegIndexes = []\n",
    " \n",
    "    pd.DataFrame(zeroIndexes).to_csv('zero indexes_(-1 and +1 model)' + str(k-1) +'_rivised.csv', index=False)\n",
    "    zeroIndexes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(zeroIndexes).to_csv('zero indexes_without softmax.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# cm = confusion_matrix(list(predicts), list((dataTest.values[:,2]+1)))\n",
    "# print(cm)\n",
    "\n",
    "# CR = classification_report(list((dataTest.values[:,2]+1)),list(predicts))\n",
    "# print(CR)\n",
    "# print(145/4702)\n",
    "# # i=0\n",
    "# # for j in list(data.values[9500:,2]+1):\n",
    "# #     if j==1:\n",
    "# #         i +=1\n",
    "# # print(i)\n",
    "\n",
    "# # plt.show()\n",
    "# plot_confusion_matrix_from_data(list((dataTest.values[:,2]+1)), list(predicts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(predit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,0].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predit).iloc[:,1].plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16, 8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Zero Drugs')\n",
    "plt.xlabel('Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Degrassive Drugs')\n",
    "plt.xlabel('Degressive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(16,8)\n",
    "\n",
    "# matplotlib histogram\n",
    "# plt.hist(pd.DataFrame(predit).iloc[:,1], color = 'blue', edgecolor = 'black',\n",
    "#          bins = int(200))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,1], hist=True, kde=False, \n",
    "             bins=int(100), color = 'blue',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "\n",
    "sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=False, \n",
    "             bins=int(100), color = 'red',\n",
    "             hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,2], hist=True, kde=False, \n",
    "#              bins=int(100), color = 'green',\n",
    "#              hist_kws={'edgecolor':'black'})\n",
    "# sns.distplot(pd.DataFrame(predit).iloc[:,0], hist=True, kde=True, \n",
    "#              bins=int(200), color = 'darkblue', \n",
    "#              hist_kws={'edgecolor':'black'},\n",
    "#              kde_kws={'linewidth': 4})\n",
    "# Add labels\n",
    "plt.title('frequency Histogram of Drugs')\n",
    "plt.xlabel('both of Degressive and Enhancive drugs Probability')\n",
    "plt.ylabel('frequency distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
